{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "\n",
    "# Get the current and parent directory\n",
    "current_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(f'{root_dir}/utilities')\n",
    "\n",
    "from utility import *\n",
    "from utility_prompt import *\n",
    "\n",
    "from ogb.graphproppred import DglGraphPropPredDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors, Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset name\n",
    "dataset_name = \"ESOL\" # ESOL, FreeSolv, BBBP, BACE\n",
    "\n",
    "# Load dataset\n",
    "datasets = dataset = DglGraphPropPredDataset(name = f\"ogbg-mol{normalize_dataset_name(dataset_name)}\", root = f'{root_dir}/datasets/')\n",
    "# Load SMILES strings\n",
    "df = pd.read_csv(f\"{root_dir}/datasets/ogbg_mol{normalize_dataset_name(dataset_name)}/mapping/mol.csv.gz\", compression='gzip')\n",
    "SMILES = list(df[\"smiles\"])\n",
    "y = np.array(datasets.labels.reshape(1, -1).tolist()[0])\n",
    "num_data = len(y)\n",
    "print(f'Num of graphs: {num_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Concept Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of concepts\n",
    "num_properties = 20\n",
    "system_prompt_step_1 = read_prompt(dataset_name, llm_model='GPT-3.5 turbo', step_idx=1, is_system=True, dir=root_dir)\n",
    "individual_prompt_step_1 = read_prompt(dataset_name, llm_model='GPT-3.5 turbo', step_idx=1, is_individual=True, dir=root_dir).format(num_properties=num_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_list = get_completion_gpt(individual_prompt_step_1, system_prompt_step_1)\n",
    "concept_list = [concept[2:].lower() for concept in concept_list.split(\"\\n\")]\n",
    "print('- '+'\\n- '.join(concept_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Concept Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1: Direct LLM Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_step_2 = read_prompt(dataset_name, llm_model='GPT-3.5 turbo', step_idx=2, is_individual=False, dir=root_dir)\n",
    "individual_prompt_step_2 = read_prompt(dataset_name, llm_model='GPT-3.5 turbo', step_idx=2, is_individual=True, dir=root_dir)\n",
    "\n",
    "def worker(smiles):\n",
    "    try:\n",
    "        return get_completion_gpt(individual_prompt_step_2.format(compound_name=smiles, property_list='- '+'\\n- '.join(concept_list)), system_prompt_step_2)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please adjust max_workers if exceeding OpenAI rate limits\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Map the function and prompts to the executor\n",
    "    results = executor.map(worker, SMILES)\n",
    "    concept_values = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse concept values\n",
    "parsed_concept_values = []\n",
    "for values in concept_values:\n",
    "    parsed_concept_values.append(parse_entry(values.split('\\n'), concept_list))\n",
    "concept_values = pd.DataFrame(parsed_concept_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: Function Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_prompt_natural_language = read_prompt(dataset_name, strategy='func', is_system=False, step_idx=1,  dir=root_dir)\n",
    "system_prompt_function_generation = read_prompt(dataset_name, strategy='func', is_system=True, step_idx=2, dir=root_dir)\n",
    "function_prompt_function_generation = read_prompt(dataset_name, strategy='func', is_system=False, step_idx=2, dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate function\n",
    "func_list = []\n",
    "llm_model = 'gpt-4-1106-preview'\n",
    "for concept in concept_list:\n",
    "    natural_language_description = get_completion_gpt(prompt=function_prompt_natural_language.format(property_name=concept),\n",
    "                                                      model=llm_model)\n",
    "    function_output = get_completion_gpt(prompt=function_prompt_function_generation.format(property_name=concept),\n",
    "                                         system_prompt=system_prompt_function_generation,\n",
    "                                         history=[function_prompt_natural_language.format(property_name=concept), natural_language_description],\n",
    "                                         model=llm_model)\n",
    "    write_function(dataset=normalize_dataset_name(dataset_name),\n",
    "                     llm_model=llm_model,\n",
    "                     property_name=concept,\n",
    "                     description=natural_language_description,\n",
    "                     function_output=function_output)\n",
    "    print(f'Generated function for {concept}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare graph\n",
    "num_graphs = len(dataset.graphs)\n",
    "\n",
    "adjs = []\n",
    "node_features_graphs = []\n",
    "edge_features_graphs = []\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    adjs.append(dataset.graphs[i].adj().to_dense())\n",
    "    node_features_graphs.append([atom_feature_vector_to_dict_full_name(node) for node in dataset.graphs[i].ndata['feat']])\n",
    "    edge_features_graphs.append([bond_feature_vector_to_dict_full_name(edge) for edge in dataset.graphs[i].edata['feat']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load generated function into function list `func_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_values = []\n",
    "for i in range(num_graphs):\n",
    "    entry = {}\n",
    "    for concept, func in zip(concept_list, func_list):\n",
    "        entry[concept] = func(adjs[i], node_features_graphs[i], edge_features_graphs[i])\n",
    "    concept_values.append(entry)\n",
    "concept_values = pd.DataFrame(concept_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3: External Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_step_2 = read_prompt(dataset_name, strategy='tool', is_system=True, dir=root_dir)\n",
    "individual_prompt_step_2 = read_prompt(dataset_name, strategy='tool', is_system=False, dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_tool_list = get_completion_gpt(individual_prompt_step_2.format(property_list='- '+'\\n- '.join(concept_list)), system_prompt_step_2, model=\"gpt-4-1106-preview\")\n",
    "concept_tool_list = parse_tools_list(concept_tool_list.split('\\n'))\n",
    "concept_tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may ignor warnings\n",
    "parsed_concept_values = []\n",
    "for smiles in SMILES:\n",
    "    mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "    parsed_concept_values.append(get_rdkit_values(mol, concept_tool_list))\n",
    "concept_values = pd.DataFrame(parsed_concept_values).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: CM Fitting and Concept Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept values\n",
    "X = concept_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data follows the same split as DGL\n",
    "split_idx = datasets.get_idx_split()\n",
    "\n",
    "train_idx = split_idx['train'].numpy()\n",
    "valid_idx = split_idx['valid'].numpy()\n",
    "test_idx = split_idx['test'].numpy()\n",
    "\n",
    "X_train, X_valid, X_test = X[train_idx], X[valid_idx], X[test_idx]\n",
    "y_train, y_valid, y_test = y[train_idx], y[valid_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "X_train_clean, rows_filled_train = fill_nones_with_column_average(X_train)\n",
    "X_valid_clean, rows_filled_valid = fill_nones_with_column_average(X_valid)\n",
    "X_test_clean, rows_filled_test = fill_nones_with_column_average(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression / Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_regression_task = normalize_dataset_name(dataset_name) in ['esol', 'freesolv']\n",
    "is_classification_task = normalize_dataset_name(dataset_name) in ['bbbp', 'bace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_clean)\n",
    "X_valid_scaled = scaler.transform(X_valid_clean)\n",
    "X_test_scaled = scaler.transform(X_test_clean)\n",
    "\n",
    "# Use linear regression + AIC feature selction for regression tasks (ESOL, FreeSolv)\n",
    "# Use Logitic regression + RFE feature selection for classification tasks (BBBP, BACE)\n",
    "if is_regression_task:\n",
    "    # Feature selection\n",
    "    best_aic, best_concepts = select_features_AIC(X_train_scaled, y_train, X_valid_scaled, y_valid)\n",
    "    best_concept_names = [concept_list[i] for i in best_concepts]\n",
    "    non_best_concept_names = list(set(concept_list) - set(best_concept_names))\n",
    "    print(f'Best AIC: {best_aic}')\n",
    "    print(\"Best features by AIC:\", end=\"\\n  * \")\n",
    "    print(best_concept_names, sep=\"\\n  * \")\n",
    "\n",
    "    # Use selected features\n",
    "    X_train_subset = X_train_scaled[:, best_concepts]\n",
    "    X_valid_subset = X_valid_scaled[:, best_concepts]\n",
    "    X_test_subset = X_test_scaled[:, best_concepts]\n",
    "\n",
    "    # Fit and predict\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_subset, y_train)\n",
    "    \n",
    "    y_pred_test = model.predict(X_test_subset)\n",
    "    print(\"Test Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "\n",
    "elif is_classification_task:\n",
    "    # feature selection\n",
    "    best_auc, best_concepts = select_features_RFE(X_train_scaled, y_train, X_valid_scaled, y_valid)\n",
    "    best_concept_names = [concept_list[i] for i in best_concepts]\n",
    "    non_best_concept_names = list(set(concept_list) - set(best_concept_names))\n",
    "    print(f'Best AUC-ROC: {best_auc}')\n",
    "    print(\"Best features by RFE:\", end=\"\\n  * \")\n",
    "    print(best_concept_names, sep=\"\\n  * \")\n",
    "\n",
    "    # Use selected features\n",
    "    X_train_subset = X_train_scaled[:, best_concepts]\n",
    "    X_valid_subset = X_valid_scaled[:, best_concepts]\n",
    "    X_test_subset = X_test_scaled[:, best_concepts]\n",
    "\n",
    "    # Fit and predict\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_subset, y_train)\n",
    "\n",
    "    y_pred_test = model.predict(X_test_subset)\n",
    "    print(f'Test AUC-ROC: {roc_auc_score(y_test, y_pred_test)}')\n",
    "else:\n",
    "    print(\"Warning: invalid dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation sets and create PredefinedSplit\n",
    "# Define a range of alpha values to explore\n",
    "alpha_values = [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 30, 50, 80]\n",
    "\n",
    "# Create an MLPRegressor instance\n",
    "if is_regression_task:\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(200,), max_iter=5000, solver=\"adam\", learning_rate_init=1e-4)\n",
    "elif is_classification_task:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(200,), max_iter=5000, solver=\"adam\", learning_rate_init=1e-4)\n",
    "\n",
    "X_combined = np.vstack((X_train_scaled, X_valid_scaled))\n",
    "y_combined = np.hstack((y_train, y_valid))\n",
    "split_index = [-1]*len(X_train_scaled) + [0]*len(X_valid_scaled)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "param_grid = {'alpha': alpha_values}\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=pds)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "if is_regression_task:\n",
    "    # Fit and predict\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(200,), max_iter=5000, solver=\"adam\", learning_rate_init=1e-4, alpha=grid_search.best_params_['alpha'])\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = mlp.predict(X_test_scaled)\n",
    "    print(\"Test: Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "elif is_classification_task:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(200,), max_iter=5000, solver=\"adam\", learning_rate_init=1e-4, alpha=grid_search.best_params_['alpha'])\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred_test = mlp.predict(X_test_scaled)\n",
    "    print(f'Test AUC-ROC: {roc_auc_score(y_test, y_pred_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Concept Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_prompt_step_3 = read_prompt(dataset_name, llm_model='GPT-3.5 turbo', step_idx=3, is_individual=True, dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_concept_list = get_completion_gpt(individual_prompt_step_3.format(best_features='\\n - '+'\\n - '.join(best_concept_names)+'\\n', non_best_features= non_best_concept_names, num_features=len(non_best_concept_names)), system_prompt_step_1)\n",
    "new_concept_list = [concept[2:].lower() for concept in new_concept_list.split(\"\\n\")]\n",
    "print('- '+'\\n- '.join(new_concept_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please repeat Step 1 to generate concept values for new features ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoMolCo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
